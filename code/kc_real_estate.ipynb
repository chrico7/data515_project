{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# King County Real Estate Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" one line summary.\n",
    "\n",
    "overall description of the module or program.  Optionally, it may also\n",
    "contain a brief description of exported classes and functions and/or usage\n",
    "examples.\n",
    "\n",
    "    Typical Usage Example:\n",
    "    \n",
    "    foo = ClassFoo()\n",
    "    bar = foo.FunctionBar()\n",
    "\"\"\"\n",
    "\n",
    "# Import packages\n",
    "import requests\n",
    "import io\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "# Define functions\n",
    "def get_county_data(file_name, num_rows=None):\n",
    "    \"\"\" Retrieves a single data-file from the King County Assessors webstie.\n",
    "    Retrieves the single data-file from the King County Assessors webstie\n",
    "    defined by file_name using the Pandas read_csv() function\n",
    "    Args:\n",
    "        file_name: The name of the file to download.\n",
    "                   Spaces will be properly formatted\n",
    "        num_rows: The number of rows to return.\n",
    "    Returns:\n",
    "        A Pandas dataframe containing all columns of the data retreived from\n",
    "        the King County Assessor's webstie and number of rows equal to\n",
    "        num_rows (defaults to all).\n",
    "    Raises:\n",
    "        ValueError: If passed file_name is not a string.\n",
    "        ValueError: If passed file_name is not valid.\n",
    "        ValueError: If passed num_rows is not a positive integer.\n",
    "        OSError: If a connection to the URL is unable to be established.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize dataframe\n",
    "    data_raw = pd.DataFrame()\n",
    "\n",
    "    # Check inputs\n",
    "    valid_names = ['Accessory', 'Apartment%20Complex', 'Change%20History',\n",
    "                   'Change%20History%20Detail', 'Commercial%20Building',\n",
    "                   'Condo%20Complex%20and%20Units',\n",
    "                   'District%20Levy%20Reference',\n",
    "                   'Environmental%20Restriction',\n",
    "                   'Home%20Improvement%20Applications',\n",
    "                   'Home%20Improvement%20Exemptions', 'Legal', 'Lookup',\n",
    "                   'Notes', 'Parcel', 'Permit', 'Real%20Property%20Account',\n",
    "                   'Real%20Property%20Appraisal%20History',\n",
    "                   'Real%20Property%20Sales', 'Residential%20Building',\n",
    "                   'Review%20History', 'Tax%20Data', 'Unit%20Breakdown',\n",
    "                   'Vacant%20Lot', 'Value%20History']\n",
    "\n",
    "    if not isinstance(file_name, str):\n",
    "        raise ValueError('Passed file_name must be of type string')\n",
    "\n",
    "    file_name = file_name.replace(' ', '%20')\n",
    "\n",
    "    if file_name not in valid_names:\n",
    "        raise ValueError('The file name you\\'ve entered is not valid. ' +\n",
    "                         'Please check ' +\n",
    "                         'https://info.kingcounty.gov/assessor/' +\n",
    "                         'DataDownload/default.aspx for correct file name')\n",
    "\n",
    "    if num_rows is not None:\n",
    "        if not isinstance(num_rows, int) & (num_rows > 0):\n",
    "            raise ValueError('Number or rows to return must be a positive' +\n",
    "                             f'integer not {num_rows}')\n",
    "\n",
    "    # Define base URL\n",
    "    url = f'https://aqua.kingcounty.gov/extranet/assessor/{file_name}.zip'\n",
    "\n",
    "    # Read in the data\n",
    "    try:\n",
    "        data_raw = pd.read_csv(url,\n",
    "                               nrows=num_rows,\n",
    "                               low_memory=False)\n",
    "\n",
    "    except OSError:\n",
    "        # try three more times with delay\n",
    "        for i in range(3):\n",
    "            time.sleep(1)\n",
    "            try:\n",
    "                data_raw = pd.read_csv(url,\n",
    "                                       nrows=num_rows,\n",
    "                                       low_memory=False)\n",
    "            except OSError:\n",
    "                pass\n",
    "        if data_raw.empty:\n",
    "            raise OSError('King County Assessor\\'s page could not be ' +\n",
    "                          'reached. Please check that ' +\n",
    "                          'https://info.kingcounty.gov/assessor/' +\n",
    "                          'DataDownload/default.aspx is available')\n",
    "\n",
    "    except UnicodeDecodeError:\n",
    "        # change encoding to latin-1 in read_csv\n",
    "        data_raw = pd.read_csv(url,\n",
    "                               nrows=num_rows,\n",
    "                               encoding='latin-1',\n",
    "                               low_memory=False)\n",
    "\n",
    "    # Check result and return\n",
    "    if data_raw.shape[0] == 0:\n",
    "        raise RuntimeError('No data was returned. Please try again later.')\n",
    "\n",
    "    return data_raw\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    try:\n",
    "        return get_data_from_Redfin()\n",
    "    except ValueError:\n",
    "        return get_data_from_file()\n",
    "\n",
    "\n",
    "def get_data_from_file():\n",
    "    current_path = os.getcwd()\n",
    "    parent_path = os.path.abspath(os.path.join(current_path, os.pardir))\n",
    "    data_path = os.path.join(parent_path, \"data\")\n",
    "    redfin_path = os.path.join(data_path,\"redfin\")\n",
    "    file_path = os.path.join(redfin_path, \"All_King_Redfin.csv\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_data_from_Redfin():\n",
    "    all_king_url = \"https://www.redfin.com/stingray/api/gis-csv?al=1&cluster_bounds=-123.04941%2046.84777%2C-121.01694%2046.84777%2C-121.01694%2047.92442%2C-123.04941%2047.92442%2C-123.04941%2046.84777&market=seattle&min_stories=1&num_homes=5000&ord=redfin-recommended-asc&page_number=1&region_id=118&region_type=5&sf=1,2,3,5,6,7&status=1&uipt=1,2,3,4,5,6&v=8\"\n",
    "    urlData = requests.get(all_king_url).content\n",
    "    if \"spam bot\" in str(urlData):\n",
    "        raise ValueError(\"Redfin api error\")\n",
    "    else:\n",
    "        return pd.read_csv(io.StringIO(urlData.decode('utf-8')))\n",
    "\n",
    "\n",
    "#def filter_county_data(zip_code: list, start_year='2010', start_month='1', start_day='1',\n",
    "#                       end_year='2020', end_month='1', end_day='1'):\n",
    "def filter_county_data(df_sale, df_building, df_parcel, df_lookup, \n",
    "                       zip_code: list, start_year='2010', start_month='1', start_day='1',\n",
    "                       end_year='2020', end_month='1', end_day='1'):\n",
    "    \"\"\" Cleans and organizes data retrieved from the King County Assessors website.\n",
    "    \n",
    "    Renames columns consistently, filters data using default and customizable inputs,\n",
    "    merges data to a single csv file.\n",
    "    \n",
    "    Args:\n",
    "        zip_code(list): List of zip codes in the King County.\n",
    "        start_year(str): Include property sale data from this year.\n",
    "        start_month(str): Include property sale data from this month.\n",
    "        start_day(str): Include property sale data from this day.\n",
    "        end_year(str): Include property sale data to this year.\n",
    "        end_month(str): Include property sale data to this month.\n",
    "        end_day(str): Include property sale data to this day.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas dataframe containing all the data retrieved from\n",
    "        the King County Assessor's website, filtered and merged.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If passed zip code is not valid.\n",
    "        ValueError: If passed start_year is before the first record.\n",
    "        ValueError: If passed end_year is after the last record.\n",
    "        ValueError: If start date is after end date based on passed values.\n",
    "    \"\"\"\n",
    "    \n",
    "    ## get data using get_county_data()\n",
    "    #df_sale = get_county_data(\"Real%20Property%20Sales\")\n",
    "    #df_building = get_county_data(\"Residential%20Building\")\n",
    "    #df_parcel = get_county_data(\"Parcel\")\n",
    "    #df_lookup = get_county_data(\"Lookup\")\n",
    "\n",
    "    df_sale = df_sale[df_sale['Major'] != '      ']\n",
    "    df_sale = df_sale.astype({'Major': int, 'Minor': int})\n",
    "\n",
    "    #df_lookup_items = pd.read_csv('../data/look_up_item.csv')\n",
    "    #df_col_names = pd.read_csv('../data/column_names.csv')\n",
    "    \n",
    "    df_lookup_items = pd.read_csv('https://raw.githubusercontent.com/chrico7/data515_project/master/data/look_up_item.csv')\n",
    "    df_col_names = pd.read_csv('https://raw.githubusercontent.com/chrico7/data515_project/master/data/column_names.csv')\n",
    "\n",
    "    df_sale.columns = df_col_names[df_col_names['source'] == 'sale'].name.tolist()\n",
    "    df_building.columns = df_col_names[df_col_names['source'] == 'building'].name.tolist()\n",
    "    df_parcel.columns = df_col_names[df_col_names['source'] == 'parcel'].name.tolist()\n",
    "    df_lookup.columns = df_col_names[df_col_names['source'] == 'lookup'].name.tolist()\n",
    "\n",
    "    df_lookup['Look Up Description'] = df_lookup['Look Up Description'].str.strip()\n",
    "\n",
    "    # get valid zip codes in King County\n",
    "    kc_zip_codes = df_building['Zip code'].dropna().unique()\n",
    "    index = []\n",
    "    for i in range(len(kc_zip_codes)):\n",
    "        if type(kc_zip_codes[i]) == float:\n",
    "            kc_zip_codes[i] = int(kc_zip_codes[i])\n",
    "            kc_zip_codes[i] = str(kc_zip_codes[i])\n",
    "        if kc_zip_codes[i][:2] != '98' or (len(kc_zip_codes[i]) != 5 and len(kc_zip_codes[i]) != 10):\n",
    "            index.append(i)\n",
    "    valid_zip = np.delete(kc_zip_codes, index)\n",
    "    for i in range(len(valid_zip)):\n",
    "        if len(valid_zip[i]) == 10:\n",
    "            valid_zip[i] = valid_zip[i][:5]\n",
    "\n",
    "    # check zip code(s)\n",
    "    for code in zip_code:\n",
    "        if code not in np.unique(valid_zip):\n",
    "            raise ValueError('The zip code ' + str(code) + ' you\\'ve entered is not in King County')\n",
    "\n",
    "    # check dates\n",
    "    df_sale['Document Date'] = pd.to_datetime(df_sale['Document Date'])\n",
    "    start_date = start_year + '-' + start_month + '-' + start_day\n",
    "    end_date = end_year + '-' + end_month + '-' + end_day\n",
    "\n",
    "    begin_year = df_sale.sort_values(['Document Date'], ascending=[True])['Document Date'].iloc[0].year\n",
    "    end_year = df_sale.sort_values(['Document Date'], ascending=[True])['Document Date'].iloc[-1].year\n",
    "    if int(start_year) < int(begin_year):\n",
    "        raise ValueError('There is no record before year' + str(begin_year))\n",
    "    if int(start_year) > int(end_year):\n",
    "        raise ValueError('There is no record after year' + str(end_year))\n",
    "    if datetime.date(int(start_year), int(start_month), int(start_day)) > \\\n",
    "            datetime.date(int(end_year), int(end_month), int(end_day)):\n",
    "        raise ValueError('Start date is after end date')\n",
    "\n",
    "    # clean up the data\n",
    "    df_building['Zip code'] = pd.to_numeric(df_building['Zip code'], errors='coerce')\n",
    "    df_building = df_building.dropna(subset=['Zip code'])\n",
    "    df_building['Zip code'] = df_building['Zip code'].astype(int)\n",
    "    df_building['Zip code'] = df_building['Zip code'].astype(str)\n",
    "\n",
    "    # limit properties to only single family houses\n",
    "    df_parcel_sf = df_parcel[df_parcel['Property Type'] == 'R']\n",
    "    df_parcel_sf = df_parcel_sf.drop(columns=['Property Type'])\n",
    "    df_sale_sf = df_sale[df_sale['Property Type'] == 11]\n",
    "    df_building_sf = df_building[df_building['Number Living Units'] == 1]\n",
    "\n",
    "    # filter by a start date and end date\n",
    "    df_sale_sf_recent = df_sale_sf[df_sale_sf['Document Date'] >= start_date]\n",
    "    df_sale_sf_recent = df_sale_sf_recent[df_sale_sf_recent['Document Date'] <= end_date]\n",
    "\n",
    "    # filter by zip code(s)\n",
    "    df_building_sf_zip = pd.DataFrame()\n",
    "    for code in zip_code:\n",
    "        df_building_sf_zip = df_building_sf_zip.append(df_building_sf[df_building_sf['Zip code'] == code])\n",
    "\n",
    "    new_df = pd.merge(df_sale_sf_recent, df_building_sf_zip, how='left', left_on=['Major', 'Minor'], right_on=['Major', 'Minor'])\n",
    "    df_all = pd.merge(new_df, df_parcel_sf, how='left', left_on=['Major', 'Minor'], right_on=['Major', 'Minor'])\n",
    "\n",
    "    # replace numerical codes in records to readable descriptions\n",
    "    for col in df_all.columns:\n",
    "        if col in df_lookup_items['Field Name'].tolist():\n",
    "            look_up_type = int(df_lookup_items[df_lookup_items['Field Name'] == col]['Look Up'])\n",
    "            look_up_items = df_lookup[df_lookup['Look Up Type'] == look_up_type]\n",
    "            description_list = []\n",
    "            for i in range(len(df_all[col])):\n",
    "                num = df_all[col].iloc[i]\n",
    "                description = look_up_items[look_up_items['Look Up Item'] == num]['Look Up Description']\n",
    "                if len(description) == 0:\n",
    "                    description_list.append('nan')\n",
    "                else:\n",
    "                    description_list.append(description.values[0])\n",
    "            df_all[col] = description_list\n",
    "    return df_all\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    zip_code = [str(item) for item in input(\"Enter zip code (separated by comma) : \").split()]\n",
    "#    start_year = (input(\"Enter start year: \"))\n",
    "#    start_month = (input(\"Enter start month: \"))\n",
    "#    start_day = (input(\"Enter start day: \"))\n",
    "#    end_year = (input(\"Enter end year: \"))\n",
    "#    end_month = (input(\"Enter end month: \"))\n",
    "#    end_day = (input(\"Enter end day: \"))\n",
    "#    filter_county_data(zip_code, start_year, start_month, start_day, end_year, end_month, end_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "## TEST MODULE\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in KC data\n",
    "df_sale = get_county_data(\"Real%20Property%20Sales\")\n",
    "df_building = get_county_data(\"Residential%20Building\")\n",
    "df_parcel = get_county_data(\"Parcel\")\n",
    "df_lookup = get_county_data(\"Lookup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2087147, 24), (515018, 50), (614827, 81), (1208, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sale.shape, df_building.shape, df_parcel.shape, df_lookup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Redfin data\n",
    "#df_redfin = get_data_from_Redfin()\n",
    "df_redfin = pd.read_csv('https://raw.githubusercontent.com/chrico7/data515_project/master/data/redfin/All_King_Redfin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4140, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_redfin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chrico7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:232: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\chrico7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:233: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\chrico7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "# Clean KC data\n",
    "kc_data = filter_county_data(df_sale, df_building, df_parcel, df_lookup,\n",
    "                             zip_code = ['98105'],\n",
    "                             start_year ='2019',\n",
    "                             start_month ='1',\n",
    "                             start_day = '1',\n",
    "                             end_year = '2019', end_month = '12', end_day = '31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27138, 150)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Excise Tax Number', 'Major', 'Minor', 'Document Date', 'Sale Price',\n",
       "       'Recording Number', 'Recording Volume', 'Recording Page', 'Plat Number',\n",
       "       'Plat Type',\n",
       "       ...\n",
       "       'Seismic Hazard', 'Landslide Hazard', 'Steep Slope Hazard', 'Stream',\n",
       "       'Wetland', 'Species Of Concern', 'Sensitive Area Tract',\n",
       "       'Water Problems', 'Transportation Concurrency', 'Other Problems'],\n",
       "      dtype='object', length=150)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:/Users/chrico7/Documents/__Corey Christopherson/MS Data Science/Courses/DATA 515/Final Project/'\n",
    "kc_data.to_csv(r'{}sample_data_98105_2019.csv'.format(path), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
